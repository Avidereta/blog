{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST For ML Beginners: The Bayesian way\n",
    "(c) 2017 Sreekumar Thaithara Balan, Alpha-I. Download the notebook: [https://github.com/alpha-i/blog/blob/blog_MNIST_tf_edward_I/notebooks/MNIST_For_ML_Beginners_The_Bayesian_Way.ipynb](https://github.com/alpha-i/blog/blob/blog_MNIST_tf_edward_I/notebooks/MNIST_For_ML_Beginners_The_Bayesian_Way.ipynb)\n",
    "\n",
    "This tutorial is intended for readers who are new to machine learning, TensorFlow and **Bayesian Methods**. Our intension is to create a Bayesian companion to the well known [getting started example](https://www.tensorflow.org/get_started/mnist/beginners) in TensorFlow. We highly recommended to read that tutorial as a prerequisite to this blog.\n",
    "\n",
    "For more information on a Bayesian perspective, Thomas Wiecki's blog on [Bayesian Deep Learning](http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/) and Yarin Gal's blog [What my deep model doesn't know...](http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html) are extremely useful starting points.\n",
    "\n",
    "The tutorial requires [TensorFlow](https://www.tensorflow.org/) *version 1.1.0* and [Edward](http://edwardlib.org/) *version 1.3.1*.\n",
    "\n",
    "## About this tutorial\n",
    "In this tutorial, we will learn about:\n",
    "\n",
    "+ How Bayesian statistics is related to machine learning\n",
    "+ Constructing a Bayesian model for the classification of MNIST images.\n",
    "+ Understaning how the Bayesian networks can quantify uncertainties in predictions.\n",
    "\n",
    "*For those who are eager to see why we care about uncertainties, scroll down to the bottom of this blog where we input the image of the letter **D** and ask our model to classify it. With a Bayesian model we can see how confident we are about our predictions!*\n",
    "\n",
    "## From Bayes to Brains\n",
    "\n",
    "In science we sometimes stumble upon a good solution to a problem by chance. For centuries, the paths followed by planets as they wander across the sky was evaluated using an intriguing technique known as epicycles.  An intricate series of gears can be used to predict the movement of the planets with a high degree of accuracy. It worked, even though the underlying concept of the planets rotating around the Earth is flawed.  This approach also lacked flexibility. For example, it would be hopeless at determining the motion of a newly discovered asteroid.\n",
    "\n",
    "Classical neural networks are the modern day equivalent of epicycles. They are fantastically useful, but their architectures have been derived from many trial-and-error processes: they sorely lack a rigorous theoretical foundation. This has limited their rate of development, since investigations have largely involved a lot of fumbling in the dark. However dramatic advances are possible if we can better understand the fundamental principles at work. Modern astronomy is a good case in point - once we understood that the motions of heavenly bodies are controlled by gravitational forces, we can not only have great confidence in their behaviour, but we can send out spacecraft and predict their motions too.  So, in the context of machine learning, what is the analog of Newton's laws of gravity? What tools can we use to design artificial intelligence at a fundamental level? Remarkably, the answer to this question has been known for decades: Bayesian Neural Networks (BNN). But there is a catch. Unlike the equations of Newton and Kepler, the calculations underpinning Bayesian Neural Networks are typically too complex for even today's supercomputers to handle. Instead researchers have begun to devise approximations to the full-fat BNN calculation. These highly simplistic shortcuts are often accurate enough for our purposes. In fact, as Gal \\& Ghahramani have shown, the popular dropout method  - a regularisation technique employed to avoid overfitting - is one such approximation. \n",
    "\n",
    "So what is a Bayesian Neural Network? To understand their nature, we'll begin with a brief outline of Bayesian statistics. At its core, Bayesian statistics is a tool which advises us on how we should alter our beliefs in light of new information. We start with an initial belief (the prior), combine this with the probability of the new data (or likelihood of the model given the new data), and this brings us to our new state of belief (known as the posterior distribution). More formally, the connection between these distributions is given by Bayes theorem:\n",
    "\n",
    "\\begin{equation*}\n",
    "p(x | D) = p(x) p(D|x) / p(D)\n",
    "\\end{equation*}\n",
    "\n",
    "Our brain makes use of this all the time. We quickly assess the most likely outcome based on a weighted combination of possibilities. For instance, if we hear the sound of a bear outside, we don't immediately jump to the conclusion that there actually is a grizzly lurking in the street. Because the prior probability of this hypothesis was so low to begin with, we would need very convincing evidence to overcome this belief.\n",
    "\n",
    "How does this tie in with Bayesian Neural Networks? Rather than fixing the weights of a neural network at a specific value, the Bayesian approach is to treat the weights of the network as variables, each with their own probability distributions. We must begin by imposing some prior belief on the weights $p(w)$. This is typically taken to be a multivariate Gaussian of unit variance, and this in part stems from the normalisation of the input amplitudes. Once our network learns from some training data $D$, our state of knowledge of the weights has a new distribution $p(w | D)$. When presented with a new sample $x$, the probability associated with the output is then given by\n",
    "\n",
    "\\begin{equation*}\n",
    "p(x | D) = \\int \\ldots \\int  p(x | w) p(w|D) dw_1 \\ldots dw_n\n",
    "\\end{equation*}\n",
    " \n",
    "The challenge comes when we wish to compute this integral. There are typically millions of weights in a network so this integral is often unimaginably vast. In this post we shall focus on an example which is simple enough to compute. \n",
    "\n",
    "\n",
    "## Importing data\n",
    "Let us import the [MNIST images](http://yann.lecun.com/exdb/mnist/) using the built in TensorFlow methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from edward.models import Categorical, Normal\n",
    "import edward as ed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Bayesian probabilistic model\n",
    "\n",
    "The next step in our analysis is to construct a Bayesian model. This is where the we differ from traditional way of thinking. For us, machine learning is an inference problem (see Chapters 39-41 David MacKay's [book](http://www.inference.phy.cam.ac.uk/itprnn/book.html) for a great introduction). Therefore, we need to describe our problem in terms of probabilities. For this purpose we use a framework called [Edward](http://edwardlib.org/). It is built on top of TensorFlow and hence we can easily add a probabilistic programming using TensorFlow-like constructs.\n",
    "\n",
    "Our machine learning model is a simple soft-max regression described in the TensorFlow getting started example. Since we are \"thinking\" in terms of probabilities, each parameter in our model has a probability distribution attached to it. We also need a function to quantify the probability of the observed data given a set of parameters (weights and biases in our case). This is called the likelihood of data.\n",
    "\n",
    "Corresponding to a soft-max regression, we use a Categorical likelihood function (see Chapter 2, [Machine Learning: a Probabilistic Perspective](https://www.cs.ubc.ca/~murphyk/MLbook/) by Kevin Murphy for a detailed description of Categorical distribution, also called Multinoulli distribution.). Why? This is where things get interesting. The combination of the Categorical likelihood and Gaussian priors on the weights and biases results in a log-posterior function which resembles the cross-entropy minimisation with a l2 regulariser (chapter 41 of MacKay's [book](http://www.inference.phy.cam.ac.uk/itprnn/book.html) )! We will not get more into the details now. That we will deal with in another blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.set_seed(31415)\n",
    "N = 100   # number of images in a minibatch\n",
    "D = 784   # number of features\n",
    "K = 10    # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-07cdfc1059cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fsimpson/anaconda3/lib/python3.6/site-packages/edward/models/random_variable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# need to temporarily pop value before __init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m  \u001b[0;31m# reinsert (needed for copying)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'loc'"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, D])\n",
    "w = Normal(loc=tf.zeros([D, K]), scale=tf.ones([D, K]))\n",
    "b = Normal(loc=tf.zeros(K), scale=tf.ones(K))\n",
    "y = Categorical(tf.matmul(x,w)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making inferences\n",
    "\n",
    "Now that we have the model defined, we can perform the statistical inference. In the Bayesian paradigm, our inference about the parameters after we have observed the data should be based on the posterior distribution of parameters. Our first task is to characterise the posterior distribution. In this example we will be using Variational Inference (VI) to perform this task. A quick introduction to VI can be found in [Edward's documentation](http://edwardlib.org/tutorials/variational-inference) and a detailed one in [Variational Inference: A Review for Statisticians](https://arxiv.org/abs/1601.00670) by Blei et al.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qw = Normal(loc=tf.Variable(tf.random_normal([D, K])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([D, K])))) \n",
    "qb = Normal(loc=tf.Variable(tf.random_normal([K])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([K]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ph = tf.placeholder(tf.int32, [N])\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={y:y_ph})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference.initialize(n_iter=5000, n_print=100, scale={y: float(mnist.train.num_examples) / N})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for the VI. We load up a TensorFlow session and start the iterations. This may take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in range(inference.n_iter):\n",
    "    X_batch, Y_batch = mnist.train.next_batch(N)\n",
    "    Y_batch = np.argmax(Y_batch,axis=1)\n",
    "    info_dict = inference.update(feed_dict={x: X_batch, y_ph: Y_batch})\n",
    "    inference.print_progress(info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Our Model\n",
    "We now have everything that we need to run our model on the test data, let's see how good our model is! The major difference in Bayesian model evaluation is that there is no single weight that we should use to evaluate the model. Instead we should use the distribution of weights and biases in our model so that the uncertainties in these parameters are reflected in the final prediction. Thus instead of a single prediction we get a set of predictions and their accuracies.\n",
    "\n",
    "We draw a 100 samples from the posterior distribution and see how we perform on each of these samples. *Taking samples might a slow process, may take few seconds!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = mnist.test.images\n",
    "Y_test = np.argmax(mnist.test.labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "prob_lst = []\n",
    "samples = []\n",
    "w_samples = []\n",
    "b_samples = []\n",
    "for _ in range(n_samples):\n",
    "    w_samp = qw.sample()\n",
    "    b_samp = qb.sample()\n",
    "    w_samples.append(w_samp)\n",
    "    b_samples.append(b_samp)\n",
    "    prob = tf.nn.softmax(tf.matmul( X_test,w_samp ) + b_samp)\n",
    "    prob_lst.append(prob.eval())\n",
    "    sample = tf.concat([tf.reshape(w_samp,[-1]),b_samp],0)\n",
    "    samples.append(sample.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accy_test = []\n",
    "for prob in prob_lst:\n",
    "    y_trn_prd = np.argmax(prob,axis=1).astype(np.float32)\n",
    "    acc = (y_trn_prd == Y_test).mean()*100\n",
    "    accy_test.append(acc)\n",
    "\n",
    "plt.hist(accy_test)\n",
    "plt.title(\"Histogram of prediction accuracies in the MNIST test data\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a range of accuacies for the samples. Note that posterior distributions of weights and biases refect the information gained from the entire MNIST test data. Thus the above histogram is representative of the uncertainty coming from the statistically possible range of weights and biases.\n",
    "\n",
    "We can perform a model averaging and try to get a equivalent of a classical machine learning model. We do this by stacking up the predictions of the 100 samples we took from the posterior distribution and then computing the average of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(np.mean(prob_lst,axis=0),axis=1)\n",
    "print(\"accuracy in predicting the test data = \", (Y_pred == Y_test).mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also look at the posterior distribution. Unfortunately, the number of dimensions is really **large** even for a small problem like this. So visualising them is tricky! This is where Bayesian methods show their \"weakness\". We look at the first 5 dimensions and produce a triangle plot of the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame(data = samples, index=range(n_samples))\n",
    "samples_5 = pd.DataFrame(data = samples_df[list(range(5))].values,columns=[\"W_0\", \"W_1\", \"W_2\", \"W_3\", \"W_4\"])\n",
    "g = sns.PairGrid(samples_5, diag_sharey=False)\n",
    "g.map_lower(sns.kdeplot, n_levels = 4,cmap=\"Blues_d\")\n",
    "g.map_upper(plt.scatter)\n",
    "g.map_diag(sns.kdeplot,legend=False)\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Joint posterior distribution of the first 5 weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the model know when it doesn't know?\n",
    "\n",
    "We borrow the phrase from Yarin Gal and see if we can get a sense of uncertainty in the prediction. We load up an image from the test data and see what classification we get for each sample from the posterior distribution of weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_image = X_test[0:1]\n",
    "test_label = Y_test[0]\n",
    "print('truth = ',test_label)\n",
    "pixels = test_image.reshape((28, 28))\n",
    "plt.imshow(pixels,cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sing_img_probs = []\n",
    "for w_samp,b_samp in zip(w_samples,b_samples):\n",
    "    prob = tf.nn.softmax(tf.matmul( X_test[0:1],w_samp ) + b_samp)\n",
    "    sing_img_probs.append(prob.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(sing_img_probs,axis=2),bins=range(10))\n",
    "plt.xticks(np.arange(0,10))\n",
    "plt.xlim(0,10)\n",
    "plt.xlabel(\"Accuracy of the prediction of the test digit\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model is very confident about the prediction here. For all the samples from the posterior, we predict the true value (this figure may be slightly different in different machines due to the ranom number generation).\n",
    "\n",
    "What will the model tell us if we give it **completely different data** to that which we have used for training? This is a crucial test as we need to know not only a prediction but also the confidence with which we can claim that prediction. In many Artificial Intelligence applications this information **extremely valuable**. \n",
    "\n",
    "For this test we shall use the *notMNIST* data of alphabets and see how our model reacts to this data. We can download the images from [here](http://yaroslavvb.com/upload/notMNIST/). The conversion to MNIST format is described [here](https://github.com/davidflanagan/notMNIST-to-MNIST). In this example we just use the converted data. We assume that all the required files are in the `notMNIST` folder and use the TensorFlow methods.\n",
    "\n",
    "  git clone git@github.com:davidflanagan/notMNIST-to-MNIST.git\n",
    "  mkdir notMNIST_data\n",
    "  cp notMNIST-to-MNIST/*.gz notMNIST_data\n",
    "\n",
    "We assume that the `notMNIST_data` is in the same directory as this notebook. Since the images are the same format as MNIST, we can use TensorFlow to load the images as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_mnist = input_data.read_data_sets(\"./notMNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xnm_test = not_mnist.test.images\n",
    "Ynm_test = np.argmax(not_mnist.test.labels,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now load an image from the notMNIST dataset and ask the model to classify it. As always, we use a set of samples from the posterior to perform the classifications and to see how confident our model is about the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_image = Xnm_test[0]\n",
    "test_label = Ynm_test[0]\n",
    "print('truth = ',test_label)\n",
    "pixels = test_image.reshape((28, 28))\n",
    "plt.imshow(pixels,cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nm_sing_img_probs = []\n",
    "for w_samp,b_samp in zip(w_samples,b_samples):\n",
    "    prob = tf.nn.softmax(tf.matmul( Xnm_test[0:1],w_samp ) + b_samp)\n",
    "    nm_sing_img_probs.append(prob.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(nm_sing_img_probs,axis=2),bins=range(10))\n",
    "plt.xticks(np.arange(0,10))\n",
    "plt.xlim(0,10)\n",
    "plt.xlabel(\"Accuracy of the prediction of the test letter\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows that the model is not as confident as before about the new classification. This is where the Bayesian methods can add a lot of value compared to the traditional ML methods.\n",
    "\n",
    "## Summary\n",
    "\n",
    "We have learned to construct a simple Bayesian statistical model for MNIST image classification using TensorFlow and Edward. Understanding uncertainty in statistical inference is very important for a variety of applications and we have explored some basic methods for visualising this problem.\n",
    "\n",
    "---\n",
    "\n",
    "*To finish off we watermark our environment. You will need [watermark](https://github.com/rasbt/watermark) iPython [extension](https://ipython.org/ipython-doc/3/config/extensions/index.html) to execute the following.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pandas,edward,tensorflow,seaborn,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
